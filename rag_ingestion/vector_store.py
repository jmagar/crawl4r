"""Qdrant vector store manager for RAG ingestion pipeline.

This module provides the VectorStoreManager class for managing Qdrant
collections, including collection creation, configuration, and validation.
Qdrant is used as the vector database for storing document embeddings with
metadata for semantic search and retrieval.

The VectorStoreManager handles:
- Idempotent collection creation with appropriate vector configurations
- Cosine distance metric (optimal for L2-normalized Qwen3 embeddings)
- Connection management to Qdrant server
- Vector upsert operations with retry logic and batch processing

Examples:
    Basic usage with default configuration:
        >>> manager = VectorStoreManager(
        ...     qdrant_url="http://crawl4r-vectors:6333",
        ...     collection_name="crawl4r"
        ... )
        >>> manager.ensure_collection()

    Custom vector dimensions:
        >>> manager = VectorStoreManager(
        ...     qdrant_url="http://crawl4r-vectors:6333",
        ...     collection_name="crawl4r",
        ...     dimensions=512
        ... )
        >>> manager.ensure_collection()

    Upserting vectors with metadata:
        >>> vector = [0.1] * 1024
        >>> metadata = {
        ...     "file_path_relative": "docs/test.md",
        ...     "chunk_index": 0,
        ...     "chunk_text": "Test content"
        ... }
        >>> manager.upsert_vector(vector, metadata)

Notes:
    - All embeddings from Qwen3-Embedding-0.6B are L2-normalized (unit vectors)
    - Cosine distance is used for similarity search (appropriate for normalized
      vectors)
    - The ensure_collection() method is idempotent and safe to call multiple
      times
    - Upsert operations include automatic retry with exponential backoff
"""

import hashlib
import time
import uuid
from collections.abc import Callable

from qdrant_client import QdrantClient
from qdrant_client.http.exceptions import UnexpectedResponse
from qdrant_client.models import Distance, PointStruct, VectorParams


class VectorStoreManager:
    """Manages Qdrant vector store operations for document embeddings.

    This class provides methods for creating and configuring Qdrant collections
    with appropriate vector dimensions and distance metrics for semantic search.
    It serves as the primary interface for all Qdrant database operations in the
    RAG ingestion pipeline.

    The manager handles collection lifecycle operations and ensures proper
    configuration for storing embeddings generated by the TEI service using
    the Qwen3-Embedding-0.6B model.

    Attributes:
        qdrant_url: URL of the Qdrant server (e.g., "http://crawl4r-vectors:6333")
        collection_name: Name of the Qdrant collection to manage
        dimensions: Vector embedding dimensions (default 1024 for Qwen3)
        client: QdrantClient instance for database operations

    Examples:
        Create a manager with default settings:
            >>> manager = VectorStoreManager(
            ...     qdrant_url="http://crawl4r-vectors:6333",
            ...     collection_name="crawl4r"
            ... )
            >>> manager.ensure_collection()

        Use custom dimensions for embeddings:
            >>> manager = VectorStoreManager(
            ...     qdrant_url="http://crawl4r-vectors:6333",
            ...     collection_name="crawl4r",
            ...     dimensions=512
            ... )
            >>> manager.ensure_collection()

    Notes:
        - The default dimensions (1024) match Qwen3-Embedding-0.6B output
        - Cosine distance is used because Qwen3 produces L2-normalized vectors
        - All operations are designed to be idempotent where possible
    """

    def __init__(
        self,
        qdrant_url: str,
        collection_name: str,
        dimensions: int = 1024,
    ) -> None:
        """Initialize VectorStoreManager with Qdrant connection.

        Creates a connection to the Qdrant server and stores configuration
        parameters for collection management. The connection is established
        immediately upon initialization.

        Args:
            qdrant_url: URL of the Qdrant server including protocol and port.
                Examples: "http://localhost:6333", "http://crawl4r-vectors:6333"
            collection_name: Name of the collection to manage. This should match
                the collection name configured in the application settings.
            dimensions: Vector embedding dimensions. Must match the dimension
                size of embeddings produced by your embedding model. Default is
                1024 for Qwen3-Embedding-0.6B at full dimensions.

        Raises:
            ValueError: If qdrant_url is empty or malformed.
            ConnectionError: If unable to connect to Qdrant server.

        Examples:
            Production configuration:
                >>> manager = VectorStoreManager(
                ...     qdrant_url="http://crawl4r-vectors:6333",
                ...     collection_name="crawl4r"
                ... )

            Development with custom dimensions:
                >>> manager = VectorStoreManager(
                ...     qdrant_url="http://localhost:6333",
                ...     collection_name="test-collection",
                ...     dimensions=512
                ... )

        Notes:
            - The QdrantClient connection is created synchronously
            - No validation is performed on the URL format (delegated to client)
            - The dimensions value is stored but only used when creating
              collections
        """
        self.qdrant_url = qdrant_url
        self.collection_name = collection_name
        self.dimensions = dimensions
        self.client = QdrantClient(url=qdrant_url)

    def ensure_collection(self) -> None:
        """Create collection if it does not exist (idempotent operation).

        Checks if the collection already exists in Qdrant. If not, creates
        a new collection with the configured vector dimensions and cosine
        distance metric. This method is idempotent and safe to call multiple
        times without side effects.

        The collection is configured with:
        - Vector size matching self.dimensions (default 1024 for Qwen3)
        - Cosine distance metric (optimal for L2-normalized embeddings)

        Returns:
            None. The method performs the operation silently and does not
            return a value.

        Raises:
            ConnectionError: If unable to communicate with Qdrant server.
            ValueError: If collection creation fails due to invalid parameters.

        Examples:
            First call creates the collection:
                >>> manager = VectorStoreManager(
                ...     qdrant_url="http://crawl4r-vectors:6333",
                ...     collection_name="crawl4r"
                ... )
                >>> manager.ensure_collection()  # Creates collection

            Subsequent calls are no-ops:
                >>> manager.ensure_collection()  # Skips (already exists)
                >>> manager.ensure_collection()  # Skips (already exists)

        Notes:
            - Cosine distance is used because Qwen3-Embedding-0.6B produces
              L2-normalized vectors (unit vectors with norm = 1.0)
            - The method does not verify existing collection configuration.
              If a collection exists with different parameters, it will not
              be modified
            - Collection creation is synchronous and blocks until complete
        """
        # Check if collection already exists to avoid redundant creation
        if self.client.collection_exists(self.collection_name):
            return

        # Create collection with vector configuration for Qwen3 embeddings
        # - size: Vector dimension count (must match embedding model output)
        # - distance: COSINE for normalized vectors (as opposed to EUCLID or DOT)
        self.client.create_collection(
            collection_name=self.collection_name,
            vectors_config=VectorParams(
                size=self.dimensions, distance=Distance.COSINE
            ),
        )

    def _generate_point_id(
        self, file_path_relative: str, chunk_index: int
    ) -> str:
        """Generate deterministic UUID from file path and chunk index.

        Creates a deterministic point ID by hashing the file path and chunk
        index together. This ensures that the same document chunk always
        gets the same ID, enabling idempotent upsert operations.

        Args:
            file_path_relative: Relative path to the file
            chunk_index: Index of the chunk within the file

        Returns:
            UUID string derived from SHA256 hash of file_path:chunk_index

        Examples:
            Generate point ID for first chunk:
                >>> manager = VectorStoreManager(
                ...     qdrant_url="http://crawl4r-vectors:6333",
                ...     collection_name="crawl4r"
                ... )
                >>> point_id = manager._generate_point_id("docs/test.md", 0)

        Notes:
            - Uses SHA256 for cryptographic-quality hash
            - Converts hash to UUID format for Qdrant compatibility
            - Same inputs always produce same UUID (deterministic)
        """
        # Create deterministic hash from file path and chunk index
        content = f"{file_path_relative}:{chunk_index}"
        hash_bytes = hashlib.sha256(content.encode()).digest()
        # Convert first 16 bytes to UUID (128-bit collision resistance)
        return str(uuid.UUID(bytes=hash_bytes[:16]))

    def _validate_vector(self, vector: list[float]) -> None:
        """Validate vector dimensions match collection configuration.

        Ensures the provided vector has the correct number of dimensions as
        configured for this collection. This prevents dimension mismatch errors
        when upserting vectors to Qdrant.

        Args:
            vector: Vector embedding to validate. Must be a list of floats
                with length matching self.dimensions.

        Raises:
            ValueError: If vector is empty (length 0) or has dimensions that
                don't match the collection's configured dimensions.

        Examples:
            Validate a 1024-dimensional vector:
                >>> manager = VectorStoreManager(
                ...     qdrant_url="http://crawl4r-vectors:6333",
                ...     collection_name="crawl4r",
                ...     dimensions=1024
                ... )
                >>> vector = [0.1] * 1024
                >>> manager._validate_vector(vector)  # No error

            Invalid vector dimensions:
                >>> bad_vector = [0.1] * 512
                >>> manager._validate_vector(bad_vector)  # Raises ValueError
        """
        if not vector:
            raise ValueError("Vector cannot be empty")
        if len(vector) != self.dimensions:
            raise ValueError(
                f"Vector dimension mismatch: expected {self.dimensions}, "
                f"got {len(vector)}"
            )

    def _validate_metadata(self, metadata: dict) -> None:
        """Validate metadata contains required fields for vector storage.

        Checks that all required metadata fields are present in the provided
        dictionary. These fields are essential for vector identification and
        retrieval operations.

        Args:
            metadata: Metadata dictionary to validate. Must contain all
                required fields: 'file_path_relative', 'chunk_index', and
                'chunk_text'.

        Raises:
            ValueError: If any required field is missing from the metadata
                dictionary. The error message specifies which field is missing.

        Examples:
            Valid metadata:
                >>> manager = VectorStoreManager(
                ...     qdrant_url="http://crawl4r-vectors:6333",
                ...     collection_name="crawl4r"
                ... )
                >>> metadata = {
                ...     "file_path_relative": "docs/test.md",
                ...     "chunk_index": 0,
                ...     "chunk_text": "Test content"
                ... }
                >>> manager._validate_metadata(metadata)  # No error

            Missing required field:
                >>> bad_metadata = {
                ...     "file_path_relative": "docs/test.md",
                ...     "chunk_text": "Test content"
                ... }
                >>> manager._validate_metadata(bad_metadata)  # ValueError
        """
        required_fields = ["file_path_relative", "chunk_index", "chunk_text"]
        for field in required_fields:
            if field not in metadata:
                raise ValueError(f"Metadata missing required field: {field}")

    def _retry_with_backoff(
        self, operation: Callable, max_retries: int = 3
    ) -> None:
        """Retry operation with exponential backoff on network errors.

        Executes the provided operation and retries on UnexpectedResponse
        errors (network/server errors from Qdrant). Uses exponential backoff
        to avoid overwhelming the server: 1s, 2s, 4s delays between attempts.

        Args:
            operation: Callable operation to execute with retry logic. Should
                be a function that performs a Qdrant operation (e.g., upsert).
                Must not take any arguments.
            max_retries: Maximum number of retry attempts before giving up.
                Default is 3 attempts (initial + 2 retries). Must be >= 1.

        Raises:
            RuntimeError: If all retry attempts fail. The error message
                includes the number of retries attempted and the underlying
                exception message from the last failed attempt.

        Examples:
            Retry an upsert operation:
                >>> manager = VectorStoreManager(
                ...     qdrant_url="http://crawl4r-vectors:6333",
                ...     collection_name="crawl4r"
                ... )
                >>> def upsert_op():
                ...     manager.client.upsert(
                ...         collection_name="crawl4r",
                ...         points=[...]
                ...     )
                >>> manager._retry_with_backoff(upsert_op, max_retries=3)

        Notes:
            - Only retries on UnexpectedResponse (network/server errors)
            - Other exceptions are raised immediately without retry
            - Backoff delays: 2^0=1s, 2^1=2s, 2^2=4s for attempts 0, 1, 2
            - Uses time.sleep() for delays (blocking operation)
        """
        for attempt in range(max_retries):
            try:
                operation()
                return
            except UnexpectedResponse as e:
                if attempt == max_retries - 1:
                    raise RuntimeError(
                        f"Failed after {max_retries} retries: {e}"
                    )
                # Exponential backoff: 1s, 2s, 4s
                time.sleep(2**attempt)

    def upsert_vector(self, vector: list[float], metadata: dict) -> None:
        """Upsert single vector with metadata to Qdrant.

        Validates the vector and metadata, generates a deterministic point ID,
        and upserts the vector to Qdrant with retry logic.

        Args:
            vector: Embedding vector (must match collection dimensions)
            metadata: Metadata dictionary with required fields:
                - file_path_relative: Relative path to source file
                - chunk_index: Index of chunk within file
                - chunk_text: Text content of the chunk

        Raises:
            ValueError: If vector dimensions are wrong or metadata is invalid
            RuntimeError: If upsert fails after max retries

        Examples:
            Upsert a single vector:
                >>> manager = VectorStoreManager(
                ...     qdrant_url="http://crawl4r-vectors:6333",
                ...     collection_name="crawl4r"
                ... )
                >>> vector = [0.1] * 1024
                >>> metadata = {
                ...     "file_path_relative": "docs/test.md",
                ...     "chunk_index": 0,
                ...     "chunk_text": "Test content"
                ... }
                >>> manager.upsert_vector(vector, metadata)

        Notes:
            - Point ID is deterministic (SHA256 of file_path:chunk_index)
            - Retries 3 times with exponential backoff (1s, 2s, 4s)
            - Validation happens before attempting upsert
        """
        # Validate inputs before attempting upsert
        self._validate_vector(vector)
        self._validate_metadata(metadata)

        # Generate deterministic point ID
        point_id = self._generate_point_id(
            metadata["file_path_relative"], metadata["chunk_index"]
        )

        # Create point structure
        point = PointStruct(id=point_id, vector=vector, payload=metadata)

        # Upsert with retry logic
        def upsert_operation() -> None:
            self.client.upsert(
                collection_name=self.collection_name, points=[point]
            )

        self._retry_with_backoff(upsert_operation)

    def upsert_vectors_batch(
        self, vectors_with_metadata: list[dict]
    ) -> None:
        """Upsert multiple vectors with metadata in batches.

        Validates all vectors and metadata, then upserts in batches of up to
        100 points. Each batch is retried independently on failure.

        Args:
            vectors_with_metadata: List of dictionaries with keys:
                - vector: Embedding vector (must match collection dimensions)
                - metadata: Metadata dictionary with required fields

        Raises:
            ValueError: If any vector or metadata is invalid
            RuntimeError: If any batch fails after max retries

        Examples:
            Upsert multiple vectors:
                >>> manager = VectorStoreManager(
                ...     qdrant_url="http://crawl4r-vectors:6333",
                ...     collection_name="crawl4r"
                ... )
                >>> vectors_with_metadata = [
                ...     {
                ...         "vector": [0.1] * 1024,
                ...         "metadata": {
                ...             "file_path_relative": "docs/test.md",
                ...             "chunk_index": i,
                ...             "chunk_text": f"Chunk {i}"
                ...         }
                ...     }
                ...     for i in range(5)
                ... ]
                >>> manager.upsert_vectors_batch(vectors_with_metadata)

        Notes:
            - Validates ALL vectors/metadata before upserting (all-or-nothing)
            - Splits into batches of 100 points
            - Each batch retries independently with exponential backoff
            - Empty list is handled gracefully (no-op)
        """
        # Handle empty list gracefully
        if not vectors_with_metadata:
            return

        # Validate all vectors and metadata before upserting (all-or-nothing)
        for item in vectors_with_metadata:
            self._validate_vector(item["vector"])
            self._validate_metadata(item["metadata"])

        # Create all point structures with deterministic IDs
        points = []
        for item in vectors_with_metadata:
            point_id = self._generate_point_id(
                item["metadata"]["file_path_relative"],
                item["metadata"]["chunk_index"],
            )
            point = PointStruct(
                id=point_id,
                vector=item["vector"],
                payload=item["metadata"],
            )
            points.append(point)

        # Split into batches of 100 points and upsert each batch
        batch_size = 100
        for i in range(0, len(points), batch_size):
            batch = points[i : i + batch_size]

            # Upsert batch with retry logic
            def upsert_batch_operation() -> None:
                self.client.upsert(
                    collection_name=self.collection_name, points=batch
                )

            self._retry_with_backoff(upsert_batch_operation)

    def search_similar(
        self, query_vector: list[float], top_k: int = 5
    ) -> list[dict]:
        """Search for similar vectors in the collection.

        Performs semantic similarity search using the provided query vector and
        returns the top_k most similar results with their scores and metadata.

        Args:
            query_vector: Query embedding vector for similarity search. Must
                match the collection's configured dimensions (default 1024).
            top_k: Maximum number of results to return, ordered by similarity
                score (highest first). Must be a positive integer. Default is 5.

        Returns:
            List of dictionaries containing search results. Each result has:
            - id: str - Point UUID
            - score: float - Similarity score (higher is more similar)
            - All metadata fields from the point's payload (file_path_relative,
              chunk_index, chunk_text, etc.)
            Returns empty list if no results found.

        Raises:
            ValueError: If query_vector is empty, has wrong dimensions, or
                top_k is not a positive integer.
            RuntimeError: If search fails after max retries.

        Examples:
            Search for similar chunks:
                >>> manager = VectorStoreManager(
                ...     qdrant_url="http://crawl4r-vectors:6333",
                ...     collection_name="crawl4r"
                ... )
                >>> query_vector = [0.1] * 1024
                >>> results = manager.search_similar(query_vector, top_k=5)
                >>> for result in results:
                ...     print(f"Score: {result['score']}")
                ...     print(f"File: {result['file_path_relative']}")
                ...     print(f"Text: {result['chunk_text']}")

            Search with custom top_k:
                >>> results = manager.search_similar(query_vector, top_k=10)
                >>> print(f"Found {len(results)} results")

        Notes:
            - Results are automatically sorted by score (highest first) by Qdrant
            - Returns empty list for empty collection (no error)
            - Retries 3 times with exponential backoff on network errors
            - All payload fields are included in results
        """
        # Validate query vector dimensions
        self._validate_vector(query_vector)

        # Validate top_k is positive
        if top_k <= 0:
            raise ValueError("top_k must be a positive integer")

        # Perform search with retry logic
        search_results = []

        def search_operation() -> None:
            nonlocal search_results
            search_results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                limit=top_k,
            )

        self._retry_with_backoff(search_operation)

        # Transform ScoredPoint results to list of dicts
        results = []
        for point in search_results:
            result = {
                "id": str(point.id),
                "score": point.score,
                **point.payload,  # Include all metadata fields
            }
            results.append(result)

        return results
