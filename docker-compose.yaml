<<<<<<< HEAD
# docker-compose.yaml
# Last Updated: 01/14/2026

name: crawl4r

x-common-service: &common-service
  labels:
    - "com.centurylinklabs.watchtower.enable=false"
  restart: unless-stopped
  env_file:
    - .env
  networks:
    - crawl4r

x-gpu-service: &gpu-service
  <<: *common-service
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            device_ids: ['0']
            capabilities: [gpu]

services:
  # ============================================================================
  # TEI EMBEDDINGS - DISABLED (RUNS ON REMOTE GPU MACHINE)
  # ============================================================================
  # TEI is NOT running locally anymore. It runs on steamy-wsl (RTX 4070 12GB)
  # at http://100.74.16.82:52000 for 2.8x better performance (59 emb/s vs 21 emb/s).
  #
  # The local RTX 3050 8GB cannot keep up with the crawl+embed pipeline.
  # Remote deployment provides:
  # - 12GB VRAM (vs 8GB local) = larger batch sizes (192 vs 96)
  # - 2x parallel batches without OOM
  # - 44% faster total pipeline (37.7s vs 67.3s for 100 URLs)
  #
  # Remote stack managed at: steamy-wsl:/home/jmagar/compose/crawl4r/
  # To re-enable local TEI, uncomment below and update .env TEI_ENDPOINT_HOST
  # ============================================================================
  # crawl4r-embeddings:
  #   <<: *gpu-service
  #   image: ghcr.io/huggingface/text-embeddings-inference:86-1.8
  #   container_name: crawl4r-embeddings
  #   environment:
  #     - CUDA_VISIBLE_DEVICES=0
  #   ports:
  #     - "${TEI_HTTP_PORT:-52000}:80"
  #   volumes:
  #     - /home/jmagar/appdata/crawl4r-embeddings:/data
  #   command:
  #     - --model-id
  #     - ${TEI_EMBEDDING_MODEL:-Qwen/Qwen3-Embedding-0.6B}
  #     - --dtype
  #     - float16
  #     - --default-prompt
  #     - "Instruct: Given a web search query, retrieve relevant passages that answer the query\nQuery: "
  #     - --max-concurrent-requests
  #     - "${TEI_MAX_CONCURRENT_REQUESTS:-128}"
  #     - --max-batch-tokens
  #     - "${TEI_MAX_BATCH_TOKENS:-131072}"
  #     - --max-batch-requests
  #     - "${TEI_MAX_BATCH_REQUESTS:-32}"
  #     - --max-client-batch-size
  #     - "${TEI_MAX_CLIENT_BATCH_SIZE:-128}"
  #     - --pooling
  #     - ${TEI_POOLING:-last-token}
  #     - --tokenization-workers
  #     - "${TEI_TOKENIZATION_WORKERS:-8}"
  #     - --auto-truncate
  #     - --json-output
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:80/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 20s

  crawl4r-vectors:
    <<: *gpu-service
    image: qdrant/qdrant:gpu-nvidia-latest
    container_name: crawl4r-vectors
    ports:
      - "${QDRANT_HTTP_PORT:-52001}:6333"
      - "${QDRANT_GRPC_PORT:-52002}:6334"
    volumes:
      - /home/jmagar/appdata/crawl4r-vectors:/qdrant/storage
    healthcheck:
      test:
        [
          "CMD",
          "bash",
          "-c",
          "echo -e 'GET /readyz HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n' | bash -c 'exec 3<>/dev/tcp/localhost/6333; cat >&3; head -1 <&3' | grep -q '200 OK'",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  crawl4r-db:
    <<: *common-service
    image: postgres:15-alpine
    container_name: crawl4r-db
    ports:
      - "${POSTGRES_PORT:-53432}:5432"
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-crawl4r}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - /home/jmagar/appdata/crawl4r-db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5

  crawl4r-cache:
    <<: *common-service
    image: redis:7-alpine
    container_name: crawl4r-cache
    ports:
      - "${REDIS_PORT:-53379}:6379"
    command: ["redis-server", "--maxmemory", "${REDIS_MAX_MEMORY:-2gb}", "--maxmemory-policy", "allkeys-lru"]
    volumes:
      - /home/jmagar/appdata/crawl4r-cache:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  crawl4ai:
    <<: *common-service
    image: ${CRAWL4AI_IMAGE:-unclecode/crawl4ai:latest}
    container_name: crawl4ai
    ports:
      - "${CRAWL4AI_PORT:-52004}:11235"
    volumes:
      - /dev/shm:/dev/shm
    shm_size: "2gb"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11235/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    user: "appuser"

networks:
  crawl4r:
    external: true
